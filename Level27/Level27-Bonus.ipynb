{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0f32aa-e2fa-47bc-bd5c-0ba56f3d1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0087a325-8fb5-4420-9209-ffc42b9f3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[..., np.newaxis].astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2acd862-cad7-4295-98e0-0dc7addd1495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\indum\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8719 - loss: 0.4691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22420b21310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bd99f4a-bf8e-4b5c-b8b8-0e17638e6316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'mnist_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2354188580432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2354188581776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2354188581392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2354188579472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export(\"mnist_model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "558e0f9e-3358-4b06-b376-db0cf6620512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for i in range(100):\n",
    "        yield [x_train[i:i+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97495cfc-9539-4f7b-9c72-11a38c35a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"mnist_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54e31f62-eb2f-4c78-9ed1-5d83c189cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model size (KB): 29.84375\n"
     ]
    }
   ],
   "source": [
    "with open(\"mnist_model_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"Quantized model size (KB):\", os.path.getsize(\"mnist_model_int8.tflite\") / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c024501e-aecb-4407-a9e3-f6ed39e2551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"mnist_model_int8.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65a8d809-1e7f-4566-8ab9-731ebe3b8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "947b5d8a-e41a-4413-ad53-1db2e341cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "test_image = x_test[0:1].astype(np.float32)  \n",
    "test_image = np.expand_dims(test_image, axis=-1) \n",
    "test_image /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d02ee905-eb75-41b4-b7ed-2b570dda9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "test_image_int8 = test_image / input_scale + input_zero_point  \n",
    "test_image_int8 = test_image_int8.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46980f96-469d-401f-a6b2-f9227a8c2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_image_int8)\n",
    "start = time.time()\n",
    "interpreter.invoke()  \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7dd94e78-226b-401f-bd2f-af51c2a0b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "pred_label = np.argmax(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "878e5531-987b-4495-abd7-f053418c9caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n",
      "Inference Time: 0.0251 seconds\n",
      "Original SavedModel Size: 34.25 KB\n",
      "Quantized Model Size: 29.84 KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prediction: {pred_label}\")\n",
    "print(f\"Inference Time: {end - start:.4f} seconds\")\n",
    "saved_model_size = os.path.getsize(\"mnist_model/saved_model.pb\") / 1024  \n",
    "quantized_model_size = os.path.getsize(\"mnist_model_int8.tflite\") / 1024  \n",
    "print(f\"Original SavedModel Size: {saved_model_size:.2f} KB\")\n",
    "print(f\"Quantized Model Size: {quantized_model_size:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734aa025-42c3-4f55-a695-b5d0bd987d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
